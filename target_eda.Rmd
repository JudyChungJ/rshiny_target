---
title: "R Notebook"
output: html_notebook
---

# Libraries
```{r}
library(tidyverse)
library(plotly)
library(openintro) #state abb
library(dygraphs)
library(arules)
library(arulesViz)
library(igraph)
library(ggplot2)
library(ggpubr)

```

# Load in the target file
```{r}
df =read.csv('/Users/judy/Desktop/rshiny/data/target.csv')
str(df)
head(df)
```
# Clean and restructure data
```{r}
# Select Columns and rename
df = df %>% 
  select(state=Address.Subdivision,
         lat=Address.Latitude,
         lon=Address.Longitude,
         storeID=AlternateIdentifier.ID,
         open_date=LocationMilestones.OpenDate,
         type=SubTypeDescription,
         capability=AllCapability)

# change dates to datetimes
df$open_date = readr::parse_datetime(df$open_date)

# add yr column for 
df = mutate(df,open_year = format(df$open_date, "%Y")) %>% 
  mutate(open_year=(as.numeric(open_year)))

# clean capability column
df=df %>% 
  mutate(capability = gsub('\\[','', capability)) %>% 
  mutate(capability = gsub('\\]','', capability)) %>% 
  mutate(capability = gsub("', '",':', capability)) %>%
  mutate(capability = gsub("'",'', capability)) %>%
  mutate(capability = gsub(",",'', capability)) %>% 
  mutate(capability = gsub('Caf\xfc\xbe\x8e\x96\x94\xbc',
                           'Cafe',capability)) %>%
  mutate(capability = gsub( '\"DAmico & Sons Italian Kitchen\"',
                            'DAmico & Sons Italian Kitchen', capability)) %>%
  mutate(capability = gsub('Super Target','',capability)) # redundant tag in capabilty is in type col
```
# combine other data sets
```{r}
# all data from 2016
# poverty SOURCE: U.S. Bureau of the Census, Current Population Survey, Annual Social and Economic Supplements.
pov = read.csv('data/3yrave_2016_18_percentpov.csv',header = TRUE, sep = ',')
pov = dplyr::rename(pov, 'st_pov_p'=percent, 'st_pov_se'=standard_error)
pov
# read personal income and pop from bea
income_pop = read.csv('./data/personal_income.csv',header=TRUE, skip=1)[,-1]
# filter and select 2016 data
income_pop= income_pop %>% 
  select(state=GeoName, description=Description, '2016'=X2017) %>% 
  filter(state!='United States', description=='Population (persons) 1/'|
           description=='Per capita personal income (dollars) 2/')
# spead description column
income_pop= spread(income_pop, description, '2016') %>% 
  dplyr::rename('st_percap_income_usd'='Per capita personal income (dollars) 2/') %>% 
  dplyr::rename('st_pop'='Population (persons) 1/')

#combine pov and income
join1 = left_join(pov, income_pop, by='state')

# education working ages 25-64
education = read.csv('data/ed_workpop_25_64.csv',header=TRUE)[,-1]
head(education)
# filter and select 2016 data
education= education %>% 
  select(state=Location, description=Education, 
         st_n_ed=Data, TimeFrame, DataFormat) %>% 
  filter(state!='United States', description=='High school diploma or GED'|
         description=='Bachelor\'s Degree', TimeFrame=='2016', 
         DataFormat=='Percent')
# spead description column
education = spread(education, 'description', st_n_ed) %>% 
  dplyr::rename('st_bach_p'='Bachelor\'s Degree', 
                'st_hs_p'= 'High school diploma or GED')
# drop columns
education$TimeFrame=NULL
education$DataFormat=NULL

#combine join1 with education
join2= left_join(join1, education, by='state')
# change states to abbreviations
join2$state = state2abbr(join2$state)

# combine with target df
df_join=left_join(df, join2, by='state')

#write.csv(df_join,'data/clean_join_target.csv')
```



# Front page map 
```{r}
# load cleaned and joined csv
df = read.csv('/Users/judy/Desktop/rshiny/data/clean_join_target.csv')[,-1]
head(df)
min(df$open_year)
```



# scatter plot map
```{r}
dfm=df %>% 
  select(state,lat,lon,storeID,capability,open_year) %>% 
  filter(state!='AK',state!='HI')
# separate by ':', then gather and drop key column
into=c('v1','v2','v3','v4','v5','v6','v7','v8','v9','v10','v11','v12','v13','v14','v15','v16','v17')
dfm=separate(dfm,capability,
              into=into,sep=':', remove=TRUE)

dfm=gather(dfm, key='col', value='capability', v1:v17, na.rm=TRUE)

dfm$col = NULL

# the shiny part for input slider
# capability or 'input tag'
dfmap = dfm %>% 
  filter(open_year<=2000) %>% 
  filter(capability==capability)

#write.csv(dfm,'data/map_target.csv')


ggplot() + 
  geom_polygon(data = map_data("usa"), aes(x=long, y = lat, group = group),
               fill = '#FFFFFF', color = '#959595') + 
  geom_polygon(data = map_data("state"),aes(x = long, y = lat, group = group),
               fill ='#FFFFFF', color = '#959595',size=0.2) +
  coord_fixed(1.3) +
  geom_point(dfmap, mapping = aes(x=lon, y=lat),color='#CC0000',size=0.9) + 
  xlab("") +
  ylab("") +
  theme_bw() +
  coord_map() +
  ggtitle("Targets Across the US") + 
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        panel.border = element_blank(),
        panel.grid.major = element_blank(),
        plot.title = element_text(hjust = 0.5))
# check capability tags
unique(dfmap$capability)


```

# bar with percapita for states
```{r}
df %>% 
  filter(st_pop!=is.na(st_pop)) %>% 
  group_by(state) %>% 
  dplyr::summarise(st_pop_1m = st_pop/1000000,
                st_nstore=n(),
                st_percap=st_nstore/mean(st_pop_1m)) %>% 
  distinct() %>% 
  arrange(desc(st_percap)) %>% 
  head(.,20) %>% 
  ggplot(aes(x=reorder(state, -st_percap),y=st_percap))+
  geom_col(fill= '#CC0000')+
  theme_bw()+
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        plot.title = element_text(hjust = 0.5))+
  ylab('Stores per Million People')+
  xlab('US States')+
  ggtitle('Stores Per Capita')

```


# scatterplots
```{r}

# next two blocks going into shiny
df3=df %>% 
  filter(st_pop!=is.na(st_pop)) %>% 
  group_by(state) %>% 
  dplyr::mutate(st_pop_1m = st_pop/1000000,
                st_nstore=n(),
                st_percap=st_nstore/mean(st_pop))

df3 %>% 
  ggplot(aes(x=st_pop_1m, y=st_nstore))+
  geom_point(color='#CC0000')+
  geom_smooth(method='lm', color='#000000', size=0.5)+
  stat_cor(method = 'pearson')+
  theme_bw()+
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        plot.title = element_text(hjust = 0.5))+
  ylab('Number of Stores')+
  xlab('Dropdown Menu: Population in Millions')
  

df3 %>% 
  ggplot(aes(x=st_percap_income_usd, y=st_nstore))+
  geom_point()+
  geom_smooth(method='lm')+
  stat_cor(method = 'pearson')

df3 %>% 
  ggplot(aes(x=st_bach_p, y=st_nstore))+
  geom_point()+
  geom_smooth(method='lm', color='red')+
  stat_cor(method = 'pearson')

df3 %>% 
  ggplot(aes(x=st_hs_p, y=st_nstore))+
  geom_point()+
  geom_smooth(method='lm')+
  stat_cor(method = 'pearson')

df3 %>% 
  ggplot(aes(x=st_pov_p, y=st_nstore))+
  geom_point()+
  geom_smooth(method='lm')+
  stat_cor(method = 'pearson')

```

#boxplots with above and below average per cap
```{r}
# bargraph
df3 %>%
  summarise(mean(st_percap))
  dplyr::arrange('st_percap')
  ggplot(aes(x= state, y=st_percap))+
  geom_col(mapping =aes(y =order(desc('st_percap'))))

df3 %>% 
  group_by(state) %>% 
  summarize(st_percap)

head(df3)
?arrange

df %>% 
  group_by(state) %>% 
  dplyr::summarize(n=n(), st_percap=n/mean(st_pop)) %>% 
  filter(st_percap!=is.na(st_percap)) %>% 
  dplyr::summarise(average(st_percap))

df3 %>% 
  filter(st_percap>=5.221428e-06) %>%
  group_by(state) %>% 
  dplyr::summarise(n=n()) %>% 
  arrange(n)

df3 %>% 
  mutate(above = st_percap>=5.221428e-06) %>% 
  ggplot()+
  geom_boxplot(aes(x=above, y=st_percap_income_usd))

f1a= df3 %>% 
  filter(st_percap>=5.221428e-06)
f1b= df3 %>% 
  filter(st_percap<5.221428e-06)

t.test(f1a$st_percap_income_usd, f1b$st_percap_income_usd)
?t.test


df3 %>% 
  mutate(above = st_percap>=5.221428e-06) %>% 
  ggplot()+
  geom_boxplot(aes(x=above, y=st_pop))

t.test(f1a$st_pop, f1b$st_pop)


df3 %>% 
  mutate(above = st_percap>=5.221428e-06) %>% 
  ggplot()+
  geom_boxplot(aes(x=above, y=st_pov_p))

t.test(f1a$st_pov_p, f1b$st_pov_p, alternative= 'two.sided')

t.test(temp$Body.Temp[temp$Gender == "Female"],
       temp$Body.Temp[temp$Gender == "Male"],
       alternative = "two.sided")

names(df3)
```

```{r}
df %>% 
  group_by(state) %>%
  dplyr::summarize(st_nstore =n(),st_pop=mean(st_pop), 
                   st_percap = (st_nstore/mean(st_pop))*100000) %>% 
  dplyr::arrange(desc(st_percap)) %>% 
  ggplot(aes(x=st_nstore, y=st_pop)) +
  geom_point()
```


# looking at tags stores with tags

```{r}
# create tag df for market basket analysis
head(temp1)
tagdf=select(temp1, storeID, capability)
head(tagdf)

# drop the storeID after checking all unique values
tagdf$storeID = NULL

# separate capability to columns
tagdf2=separate(tagdf,capability,into=into,sep=',')

# drop stores that have no tags
tagdf2= filter(tagdf2,tagdf2$v1!="")

#write.csv(tagdf2, 'tag.csv',quote = FALSE, row.names = TRUE)


# make transactions type
trans = read.transactions('tag.csv', format = 'basket', sep=',')
class(trans)
summary(trans)
# from summary

rules = apriori(trans, parameter = list(supp=0.001, conf=0.8))
rules = sort(rules, by='confidence', decreasing = TRUE)
rules = rules[!is.redundant(rules)]
summary(rules)
inspect(rules[1:20])
```
```{r}
subrules2 <- head(sort(rules, by="confidence"),30)
ig <- plot( subrules2, method="graph", control=list(type="items") )
ig_df <- get.data.frame( ig, what = "both" )
ig_df <- toVisNetworkData(ig, idToLabel = FALSE)

visNetwork(ig_df$nodes, ig_df$edges) %>%
visNodes(size = 10) %>%
visLegend() %>%
visEdges(smooth = FALSE) %>%
visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %>%
visInteraction(navigationButtons = TRUE) %>%
visEdges(arrows = 'from') %>%
visPhysics(
solver = "barnesHut",
maxVelocity = 35,
forceAtlas2Based = list(gravitationalConstant = -6000))

tagdf2 %>%
   visNodes(size = 10) %>%
   visLegend() %>%
   visEdges(smooth = FALSE) %>%
   visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %>%
   visInteraction(navigationButtons = TRUE) %>%
   visEdges(arrows = 'from') %>%
   visPhysics(
        solver = "barnesHut",
        maxVelocity = 35,
        forceAtlas2Based = list(gravitationalConstant = -6000)
      )
?get.data.frame
summary(rules)
```



```{r}
dfc %>% 
  group_by(state) %>% 
  mutate(n_state=n()) %>% 
  group_by(state,capability) %>% 
  summarise(norm_cap=mean(n()/n_state)) %>% 
  arrange(desc(norm_cap))

dfc %>% 
  group_by(capability) %>% 
  summarise(n=n()) %>% 
  arrange(desc(n))

dfc %>% 
  group_by(state) %>% 
  mutate(n_state=n_distinct(storeID)) %>% 
  filter(capability=='FreshGrocery') %>% 
  group_by(state) %>% 
  summarise(mean(n_state),ngrocery=n(), p_cap = mean(ngrocery/n_state)) %>% 
  arrange(desc(ngrocery))

dfc %>% 
  group_by(state) %>% 
  mutate(n_state=n_distinct(storeID)) %>% 
  filter(capability=='Bakery') %>% 
  group_by(state) %>% 
  summarise(mean(n_state),nbakery=n(), p_cap = mean(nbakery/n_state)) %>% 
  arrange(desc(nbakery))

dfc %>% 
  group_by(state) %>% 
  mutate(n_state=n_distinct(storeID)) %>% 
  filter(capability=='MinuteClinic') %>% 
  group_by(state) %>% 
  summarise(mean(n_state),nbakery=n(), p_cap = mean(nbakery/n_state)) %>% 
  arrange(desc(nbakery))

dfc %>% 
  group_by(state) %>% 
  mutate(n_state=n_distinct(storeID)) %>% 
  filter(capability=='AcceptsWIC') %>% 
  group_by(state) %>% 
  summarise(mean(n_state),nbakery=n(), p_cap = mean(nbakery/n_state)) %>% 
  arrange(desc(nbakery))

dfc %>% 
  group_by(state) %>% 
  mutate(n_state=n_distinct(storeID)) %>% 
  filter(capability=='Starbucks') %>% 
  group_by(state) %>% 
  summarise(mean(n_state),nbakery=n(), p_cap = mean(nbakery/n_state)) %>% 
  arrange(desc(nbakery))

dfc %>% 
  group_by(state) %>% 
  mutate(n_state=n_distinct(storeID)) %>% 
  filter(capability=='Optical') %>% 
  group_by(state) %>% 
  summarise(mean(n_state),nbakery=n(), p_cap = mean(nbakery/n_state)) %>% 
  arrange(desc(nbakery))

dfc %>% 
  group_by(state) %>% 
  mutate(n_state=n_distinct(storeID)) %>% 
  filter(capability=='Starbucks') %>% 
  group_by(state) %>% 
  summarise(mean(n_state),nbakery=n(), p_cap = mean(nbakery/n_state)) %>% 
  arrange(desc(nbakery))
```
# looking at store type distribution
```{r}
dfc %>% 
  group_by(type) %>% 
  summarise(n=n()) %>% 
  arrange(desc(n))

dfc %>% 
  group_by(state) %>% 
  mutate(n_state=n_distinct(storeID)) %>% 
  filter(type=='SuperTarget') %>% 
  group_by(state) %>% 
  summarise(mean(n_state),nbakery=n(), p_cap = mean(nbakery/n_state)) %>% 
  arrange(desc(nbakery))

dfc %>% 
  group_by(state) %>% 
  mutate(n_state=n_distinct(storeID)) %>% 
  filter(type=='City') %>% 
  group_by(state) %>% 
  summarise(mean(n_state),nbakery=n(), p_cap = mean(nbakery/n_state)) %>% 
  arrange(desc(nbakery))
# weirdly WA, OR west coast state have smaller city targets NY and CA have them 

dfc %>% 
  group_by(state) %>% 
  mutate(n_state=n_distinct(storeID)) %>% 
  filter(type=='TargetExpress') %>% 
  group_by(state) %>% 
  summarise(mean(n_state),nbakery=n(), p_cap = mean(nbakery/n_state)) %>% 
  arrange(desc(nbakery))
# kind of correlates with state university numbers http://www.univsearch.com/state.php

```
# opening data
```{r}


smalldf= df %>% 
  group_by(state) %>% 
  filter(n()>50) %>% 
  mutate(ns=n())

# get year column and do some exploration
mutate(df,open_year = format(df$open_date, "%Y")) %>% 
  group_by(state) %>% 
  filter(n()>60) %>% 
  group_by(state, open_year) %>% 
  summarize(n=n()) %>% 
  ggplot(aes(x=open_year, y=n))+
  geom_line(aes(color=state,group = state))+
  facet_grid(rows = 'state')
  
?text


```

```{r}
dfopen = mutate(df,open_year = format(df$open_date, "%Y")) %>% 
  group_by(state) %>% 
  filter(state=='MN') %>% 
  mutate(open_year=(as.numeric(open_year))) %>% 
  group_by(state, open_year) %>% 
  summarize(n=n())

dygraph(dfopen[,-1])

# ggplot(dfopen, aes(x=open_year, y=n))+
#   geom_line(data=dfopen[!is.na(dfopen$open_year),])
#   facet_grid(rows = 'state')



test2= mutate(df,open_year = as.numeric(format(df$open_date, "%Y"))) %>% 
  group_by(state) %>% 
  filter(state=='MN') %>% 
  group_by(state, open_year) %>% 
  summarize(n=n())

str(df)


```
```{r}
# graph year by total number of stores by that year

# add open_year col as numeric and n summarize
dfy = df %>% 
  group_by(open_year) %>% 
  summarize(n=n())
head(dfy)
# add totn column for for loop
dfyt = dfy %>% 
  mutate(totn=n)
head(dfyt)
# for loop to add previous year number of stores to current to get total stores by year
for (i in 2:length(dfyt$n)) {
  dfyt$totn[i]=dfyt$totn[i]+dfyt$totn[i-1]
}
dfyt

# line graph the total store numbers
dfyt %>% 
  ggplot(aes(x=open_year, y=totn))+
  geom_line()

```

```{r}
# graph year by total number of stores by that year and state

# add open_year col as numeric and n summarize
dfyrs = df %>% 
  group_by(state, open_year) %>% 
  summarize(n=n())

# add totn column for for loop
dfyrs = dfyrs %>% 
  mutate(totn=n)

# for loop to add previous year number of stores to current to get total stores by year
for (i in 2:length(dfyrs$n)) {
  ifelse(dfyrs$state[i]==dfyrs$state[i-1],
         (dfyrs$totn[i]=dfyrs$totn[i]+dfyrs$totn[i-1]),
         (dfyrs$totn[i]=dfyrs$totn[i]))
}
dfyrs

# line graph the total store numbers
dfyrs %>% 
  ggplot(aes(x=open_year, y=totn))+
  geom_line(aes(color=state,group = state))


```

# just a peak at the personal income and pop by year csv
```{r}
indf= read.csv('./data/personal_income.csv',header=TRUE, skip=1)[,-1]
head(indf)
header = as.character(indf[1,])
header
header = cat('placeholder', header)
length(header)
dim(indf)
indf= read.csv('./data/personal_income.csv',header=FALSE, col.names = header)[ -1,-1]
head(indf)
?read.csv
header=as.character(indf[1,])
header
indf[[1]]
```

